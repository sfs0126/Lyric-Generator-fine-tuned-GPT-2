{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lyric Generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMXo18hwpSxdex1b0/I+Spp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sfs0126/Lyric-Generator-fine-tuned-GPT-2/blob/main/Lyric_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxIugSzWf_QI"
      },
      "source": [
        "# Lyric Generation for Different Music Genres\n",
        "## Fine-Tuning GPT-2 and Evaluating with Perplexity\n",
        "### Text Generation of Popular Music Lyrics\n",
        "\n",
        "##### Lyric Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJ67LhapR00T",
        "outputId": "1bf29cd7-3183-4281-8f8e-89e92f8722fd"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 7.8 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 68.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 55.3 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 39.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 536 kB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLjBIRg_Sool",
        "outputId": "01baaa1b-f1cd-46fd-fa95-3d913b2440a2"
      },
      "source": [
        "pip install git+https://github.com/huggingface/transformers"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-q71fj12o\n",
            "  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-q71fj12o\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (4.62.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (3.4.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (0.0.46)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (4.8.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (0.10.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (0.2.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.13.0.dev0) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.13.0.dev0) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.13.0.dev0) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13.0.dev0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13.0.dev0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13.0.dev0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.13.0.dev0) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.13.0.dev0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.13.0.dev0) (1.15.0)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.13.0.dev0-py3-none-any.whl size=3276935 sha256=8670093e34a60b3b2db1c478a1068a144d89a8da47fdf240318c8ac9a7debdfe\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-w3dcskuu/wheels/35/2e/a7/d819e3310040329f0f47e57c9e3e7a7338aa5e74c49acfe522\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.12.5\n",
            "    Uninstalling transformers-4.12.5:\n",
            "      Successfully uninstalled transformers-4.12.5\n",
            "Successfully installed transformers-4.13.0.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzOWJ_61StQp"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import datetime\n",
        "from google.colab import drive\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
        "torch.manual_seed(42)\n",
        "\n",
        "from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, GPT2LMHeadModel\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIyocbDnTu2x",
        "outputId": "2ca76e69-70bb-4110-8807-b7f97c35991b"
      },
      "source": [
        "gpu_info = !nvidia-smi -L\n",
        "gpu_info = \"\\n\".join(gpu_info)\n",
        "if gpu_info.find(\"failed\") >= 0:\n",
        "    print(\"Not connected to a GPU\")\n",
        "else:\n",
        "    print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not connected to a GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNhhKyaxTOc9",
        "outputId": "6ef62f76-096d-4976-a0e8-0b2934cd75e4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python '/content/drive/MyDrive/Topics in Computing Notebooks/run_generation.py' \\\n",
        "  --model_type gpt2 \\\n",
        "  --model_name_or_path '/content/drive/MyDrive/Topics in Computing Notebooks/models/hiphop_model_finetuned' \\\n",
        "  --prompt \"<BOS>\" \\\n",
        "  --stop_token \"<EOS>\" \\\n",
        "  --k 50 \\\n",
        "  --length=500 \\\n",
        "  --num_return_sequences 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ai7DUVPSssrI",
        "outputId": "60410561-da2b-41d8-917f-fe0a5d6fb109"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/07/2021 22:40:02 - WARNING - __main__ - device: cpu, n_gpu: 0, 16-bits training: False\n",
            "12/07/2021 22:40:06 - INFO - __main__ - Namespace(device=device(type='cpu'), fp16=False, k=50, length=500, model_name_or_path='/content/drive/MyDrive/Topics in Computing Notebooks/models/hiphop_model_finetuned', model_type='gpt2', n_gpu=0, no_cuda=False, num_return_sequences=5, p=0.9, padding_text='', prefix='', prompt='<BOS>', repetition_penalty=1.0, seed=42, stop_token='<EOS>', temperature=1.0, xlm_language='')\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "=== GENERATED SEQUENCE 1 ===\n",
            "<BOS>. Girl it's funny, you wanna know what I'm talking about. But I know that there's somebody else. You never wanna fall in love with me. You just gotta let me know if you wanna. I can say what I feel like about. You tryna tryna help me, but you know that I can't do it. But I know you wanna fall in love with me. So let me know if you wanna. I can say what I feel like about. You tryna tryna help me, but you know that I can't do it. But I know you wanna fall in love with me. So let me know if you wanna. I can say what I feel like about. You tryna tryna help me, but you know that I can't do it. But I know you wanna fall in love with me. So let me know if you wanna. I can say what I feel like about. You tryna tryna help me, but you know that I can't do it. But I know you wanna fall in love with me. So let me know if you wanna. I can say what I feel like about. You tryna tryna help me, but you know that I can't do it. But I know you wanna fall in love with me. So let me know if you wanna. I can say what I feel like about. You tryna tryna help me, but you know that I can't do it. But I know you wanna fall in love with me. So let me know if you wanna. I can say what I feel like about. You tryna tryna help me, but you know that I can't do it. But I know you wanna fall in love with me. So let me know if you wanna. I can say what I feel like about. You tryna tryna help me, but you know that I can't do it. But I know you wanna fall in love with me. So let me know if you wanna. I can say what I feel like about. You tryna tryna help me, but you know that I can't do it. But I know you wanna fall in love with me. So let me know if you wanna. I can say what I feel like about. You tryna tryna help me, but you know that I can't do it. But I know you wanna fall in love with me. So let me know i\n",
            "=== GENERATED SEQUENCE 2 ===\n",
            "<BOS>  of these people. This will give me nothing for this. I don't even know what I'm talking about. All I know is that you know. All I really know is that I've been. Loving you all my life. It wasn't until this day that I was. A selfish little man. But now I don't wanna see him hurt anymore. Cause he's gone too far, I can't help it. Cause he just can't help it. Cause he's gone too far, I can't help it. Cause he just can't help it. He just can't help it. Cause he just can't help it. He just can't help it. So I just can't help it.  \n",
            "=== GENERATED SEQUENCE 3 ===\n",
            "<BOS>  by my knees, knees down. So just chill and breathe out. When I'm done with you, I'll be back in the studio. Let's go fuckin'. But I don't wanna play, I wanna play with the wrong guy. I just wanna say hello, and get fucked up. I'm not your type, you're not my type, you're not my type. If you're feeling down. It's not that hard. You got your phone, your email, your phone. Just put that shit in my ear. I'm chillin'. Just chill and breathe out. When I'm done with you, I'll be back in the studio. Let's go fuckin'. But I don't wanna play, I wanna play with the wrong guy. I just wanna say hello, and get fucked up. I'm not your type, you're not my type, you're not my type. If you're feeling down. It's not that hard. You got your phone, your email, your phone. Just put that shit in my ear. I'm chillin'. Just chill and breathe out. When I'm done with you, I'll be back in the studio. Let's go fuckin'. But I don't wanna play, I wanna play with the wrong guy. I just wanna say hello, and get fucked up. I'm not your type, you're not my type, you're not my type. If you're feeling down. It's not that hard. You got your phone, your email, your phone. Just put that shit in my ear. I'm chillin'. Just chill and breathe out. When I'm done with you, I'll be back in the studio. Let's go fuckin'. But I don't wanna play, I wanna play with the wrong guy  \n",
            "=== GENERATED SEQUENCE 4 ===\n",
            "<BOS>  a hundred and ninety percent. It'll be your turn. I need you more than I already have, and I need you more than I already have, and I need you more than I already have. Girl, I feel so good. I'm just hoping it's not too late to save. Oh, baby, it's been a long time. Girl, I feel so good. I'm just hoping it's not too late to save. Oh, baby, it's been a long time. Girl, I feel so good. I'm just hoping it's not too late to save. Oh, baby, it's been a long time. Girl, I feel so good. I'm just hoping it's not too late to save. Oh, baby, it's been a long time  \n",
            "=== GENERATED SEQUENCE 5 ===\n",
            "<BOS>  to get. Aye, aye, aye, aye, aye. And I know you have been doing a good job. But I know you're not going to let me down. I don't know how I should feel, but I know that I should. Do me. Oh, baby. Do me. Do me. Do me. Do me. Do me. Do me. Do me. Do me. Do me. I'm just saying. It's too late, baby. To get your attention, baby. To get the attention you need, baby. To get the attention you need, baby. Girl, girl, girl, girl. Let me feel you, baby. I can do it, girl, girl. I can do it. Girl, girl, girl, girl. Let me feel you, baby. I can do it, girl, girl  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python '/content/drive/MyDrive/Topics in Computing Notebooks/run_generation.py' \\\n",
        "  --model_type gpt2 \\\n",
        "  --model_name_or_path gpt2 \\\n",
        "  --prompt \"<BOS>\" \\\n",
        "  --stop_token \"<EOS>\" \\\n",
        "  --k 50 \\\n",
        "  --length=500 \\\n",
        "  --num_return_sequences 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "075d0eda-e4fa-4b9d-a7cf-47b7e9100c82",
        "id": "OEcOfHt7G0Wc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/08/2021 03:34:41 - WARNING - __main__ - device: cpu, n_gpu: 0, 16-bits training: False\n",
            "12/08/2021 03:34:47 - INFO - __main__ - Namespace(device=device(type='cpu'), fp16=False, k=50, length=500, model_name_or_path='gpt2', model_type='gpt2', n_gpu=0, no_cuda=False, num_return_sequences=5, p=0.9, padding_text='', prefix='', prompt='<BOS>', repetition_penalty=1.0, seed=42, stop_token='<EOS>', temperature=1.0, xlm_language='')\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "=== GENERATED SEQUENCE 1 ===\n",
            "<BOS> # -m,e -m,c # -m,e -m,m # -m,e -m,m,s # -m,e -m,m # -m,e -m # -m,e -m #\n",
            "\n",
            "{ -f :nf, -q :nc, -s :nj # -n :nf -f }\n",
            "\n",
            "{ -b :nf, -p :nj # -n :nf -b }\n",
            "\n",
            "{ -d :nf, -p :nj # -n :nf -d }\n",
            "\n",
            "{ -e :nf, -f :nf, -q :nf, -s :nj # -n :nf -e }\n",
            "\n",
            "{ -f :nf, -q :nf, -s :nj # -n :nf -f }\n",
            "\n",
            "{ -e :nf, -f :nf, -q :nf, -s :nj # -n :nf -e }\n",
            "\n",
            "{ -f :nf, -q :nf, -s :nj # -n :nf -e }\n",
            "\n",
            "{ -f :nf, -q :nf, -s :nj # -n :nf -f }\n",
            "\n",
            "{ -f :nf, -q :nf, -s :nj # -n :nf -e }\n",
            "\n",
            "{ -f :nf, -q :nf, -s :nj # -n :nf -e }\n",
            "\n",
            "{ -f :nf, -q :nf, -s :nj # -n :nf -e }\n",
            "\n",
            "{ -f :nf, -q :nf, -s :nj # -n :nf -e }\n",
            "\n",
            "{ -f :nf, -q :nf, -s :nj # -n :nf -e }\n",
            "\n",
            "{ -f :nf, -q :nf, -s :nj # -n :nf -e }\n",
            "\n",
            "{ -f :nf, -q :nf, -s :nj # -n :nf -e }\n",
            "\n",
            "{ -f :nf, -q \n",
            "=== GENERATED SEQUENCE 2 ===\n",
            "<BOS>\n",
            "\n",
            "</BOS>\n",
            "\n",
            "</Tables>\n",
            "\n",
            "<RowIndex>\n",
            "\n",
            "<ID>\n",
            "\n",
            "<TITLE>Hottest (8chan) hot new year</TITLE>\n",
            "\n",
            "</RowIndex>\n",
            "\n",
            "</Row>\n",
            "\n",
            "<RowIndex>\n",
            "\n",
            "<ID>\n",
            "\n",
            "<TITLE>Hottest (8chan) hot new year</TITLE>\n",
            "\n",
            "</RowIndex>\n",
            "\n",
            "</Row>\n",
            "\n",
            "</Row>\n",
            "\n",
            "<RowIndex>\n",
            "\n",
            "<ID>\n",
            "\n",
            "<TITLE>Hottest (8chan) hot new year</TITLE>\n",
            "\n",
            "</RowIndex>\n",
            "\n",
            "</Row>\n",
            "\n",
            "</Row>\n",
            "\n",
            "<RowIndex>\n",
            "\n",
            "<ID>\n",
            "\n",
            "<TITLE>Hot New Year (8chan) hot new year</TITLE>\n",
            "\n",
            "</RowIndex>\n",
            "\n",
            "</Row>\n",
            "\n",
            "<RowIndex>\n",
            "\n",
            "<ID>\n",
            "\n",
            "<TITLE>Hot New Year (8chan) hot new year</TITLE>\n",
            "\n",
            "</RowIndex>\n",
            "\n",
            "</Row>\n",
            "\n",
            "<RowIndex>\n",
            "\n",
            "<ID>\n",
            "\n",
            "<TITLE>Hot New Year (8chan) hot new year</TITLE>\n",
            "\n",
            "</RowIndex>\n",
            "\n",
            "</Row>\n",
            "\n",
            "<RowIndex>\n",
            "\n",
            "<ID>\n",
            "\n",
            "<TITLE>Hot New Year (8chan) hot new year</TITLE>\n",
            "\n",
            "</RowIndex>\n",
            "\n",
            "</Row>\n",
            "\n",
            "</Row>\n",
            "\n",
            "<RowIndex>\n",
            "\n",
            "<ID>\n",
            "\n",
            "<TITLE>Hot New Year (8chan) hot new year</TITLE>\n",
            "\n",
            "</RowIndex>\n",
            "\n",
            "</Row>\n",
            "\n",
            "</Row>\n",
            "\n",
            "<RowIndex>\n",
            "\n",
            "<ID>\n",
            "\n",
            "<TITLE>Hot New Year (8chan) hot new year</TITLE>\n",
            "\n",
            "</RowIndex>\n",
            "\n",
            "</Row>\n",
            "\n",
            "<RowIndex>\n",
            "\n",
            "<ID>\n",
            "\n",
            "<TITLE>Hot New Year (8chan) hot new year</TITLE>\n",
            "\n",
            "</RowIndex>\n",
            "\n",
            "</Row>\n",
            "\n",
            "</Row>\n",
            "\n",
            "<RowIndex>\n",
            "\n",
            "<ID>\n",
            "\n",
            "<TITLE>Hot New Year (8chan) hot new year</TITLE>\n",
            "\n",
            "</RowIndex>\n",
            "\n",
            "</Row>\n",
            "\n",
            "<Ro\n",
            "=== GENERATED SEQUENCE 3 ===\n",
            "<BOS>\n",
            "\n",
            "[2015-10-14 23:18:37] <Bos> it's ok to be offended in the first place\n",
            "\n",
            "[2015-10-14 23:18:42] <Bos> because you have the decency to say \"fuck you\" to the next person\n",
            "\n",
            "[2015-10-14 23:18:46] <Bos> and you can use your dick as much as you want but not as big\n",
            "\n",
            "[2015-10-14 23:18:50] <Bos> because you've given the guy your full attention\n",
            "\n",
            "[2015-10-14 23:19:00] <Bos> and you're so fucking horny and so horny and so horny\n",
            "\n",
            "[2015-10-14 23:19:03] <Bos> and you can use that as your fucking tool\n",
            "\n",
            "[2015-10-14 23:19:13] <Bos> if you're gonna play with me now\n",
            "\n",
            "[2015-10-14 23:19:14] <Bos> i'm making you cum\n",
            "\n",
            "[2015-10-14 23:19:21] <Bos> that's what i'm talking about\n",
            "\n",
            "[2015-10-14 23:19:33] <Bos> that's not the point, that's the point of this thread.\n",
            "\n",
            "[2015-10-14 23:19:38] <Bos> because you think your cock is good enough\n",
            "\n",
            "[2015-10-14 23:19:44] <Bos> that you're fucking beautiful, and that you're fucking beautiful and\n",
            "\n",
            "[2015-10-14 23:19:47] <Bos> that you're fucking beautiful\n",
            "\n",
            "[2015-10-14 23:19:51] <Bos> that you're fucking beautiful\n",
            "\n",
            "[2015-10-14 23:19:55] <Bos> that you're fucking beautiful\n",
            "\n",
            "[2015-10-14 23:20:06] <Bos> that you're fucking beautiful\n",
            "\n",
            "[2015-10-14 23:20:07] <Bos> and then when you say \"that's a dick\", you're fucking\n",
            "\n",
            "[2015-10-14 23:20:11] <Bos> a fucking dick\n",
            "\n",
            "[2015-10-14 23:20:13\n",
            "=== GENERATED SEQUENCE 4 ===\n",
            "<BOS> :bomber_credits| :bomber_says_to_the_death| :bomber_takes_a_snow| :bomber_gave_a_blow| :bomber_says_to_the_death| :bomber_takes_a_slap| :bomber_says_to_the_death| :bomber_takes_a_mock_of_a| :bomber_says_to_the_death| :bomber_says_to_the_death| :bomber_says_to_the_death| :bomber_says_to_the_death| :bomber_says_to_the_death| :bomber_says_to_the_death| :bomber_says_to_the_death| :bomber_says_to_the_death| :bomber_says_to_the_death| :bomber_says_to_the_death| :bomber_says_to_the_death| :bomber_says_to_the_death| :bomber_says_to_the_death| :bomber_says_to_the_death| :bomber_says_to_the_death| :bomber_says_to_the_death| :bomber_says_to_the_death| :bomber_says_to_the_death| :bomber_says_to_the_death| :bomber_says_to_the_death| :bomber_says_to_the_death| :bomber_says_to_the_death| :bomber_says_to_the_death| :bomber_says_to_the_death| :bomber_says_to_the_death| :bomber_says_to_the_death| :bomber_says_to_the_death| :bomber_says_to_the_death| :bo\n",
            "=== GENERATED SEQUENCE 5 ===\n",
            "<BOS> $foo ( \\.foo ) -> { $foo = $foo + 1 }\n",
            "\n",
            "$foo $foo 1 {1} $foo 2 {2} 1 2 3 $foo 2 1\n",
            "\n",
            "$foo\n",
            "\n",
            "( \\.foo ) -> { $foo = $foo + 1 }\n",
            "\n",
            "$foo + 1\n",
            "\n",
            "$foo\n",
            "\n",
            "( \\.foo ) -> { $foo = $foo + 1 }\n",
            "\n",
            "$foo + 1\n",
            "\n",
            "$foo\n",
            "\n",
            "( \\.foo ) -> { $foo = $foo + 1 }\n",
            "\n",
            "$foo + 1\n",
            "\n",
            "$foo + 2\n",
            "\n",
            "$foo + 3\n",
            "\n",
            "$foo + 4\n",
            "\n",
            "$foo + 5\n",
            "\n",
            "$foo + 6\n",
            "\n",
            "$foo + 7\n",
            "\n",
            "$foo + 8\n",
            "\n",
            "$foo + 9\n",
            "\n",
            "$foo + 10\n",
            "\n",
            "$foo + 11\n",
            "\n",
            "$foo + 12\n",
            "\n",
            "$foo + 13\n",
            "\n",
            "$foo + 14\n",
            "\n",
            "$foo + 15\n",
            "\n",
            "$foo + 16\n",
            "\n",
            "$foo + 17\n",
            "\n",
            "$foo + 18\n",
            "\n",
            "$foo + 19\n",
            "\n",
            "$foo + 20\n",
            "\n",
            "$foo + 21\n",
            "\n",
            "$foo + 22\n",
            "\n",
            "$foo + 23\n",
            "\n",
            "$foo + 24\n",
            "\n",
            "$foo + 25\n",
            "\n",
            "$foo + 26\n",
            "\n",
            "$foo + 27\n",
            "\n",
            "$foo + 28\n",
            "\n",
            "$foo + 29\n",
            "\n",
            "$foo + 30\n",
            "\n",
            "$foo + 31\n",
            "\n",
            "$foo + 32\n",
            "\n",
            "$foo + 33\n",
            "\n",
            "$foo + 34\n",
            "\n",
            "$foo + 35\n",
            "\n",
            "$foo + 36\n",
            "\n",
            "$foo + 37\n",
            "\n",
            "$foo + 38\n",
            "\n",
            "$foo + 39\n",
            "\n",
            "$foo + 40\n",
            "\n",
            "$foo + 41\n",
            "\n",
            "$foo + 42\n",
            "\n",
            "$foo + 43\n",
            "\n",
            "$foo + 44\n",
            "\n",
            "$foo + 45\n",
            "\n",
            "$foo + 46\n",
            "\n",
            "$foo + 47\n",
            "\n",
            "$foo + 48\n",
            "\n",
            "$foo + 49\n",
            "\n",
            "$foo + 50\n",
            "\n",
            "$foo + 51\n",
            "\n",
            "$foo + 52\n",
            "\n",
            "$foo + 53\n",
            "\n",
            "$foo + 54\n",
            "\n",
            "$foo + 55\n",
            "\n",
            "$foo + 56\n",
            "\n",
            "$foo + 57\n",
            "\n",
            "$foo + 58\n",
            "\n",
            "$foo + 59\n",
            "\n",
            "$foo + 60\n",
            "\n",
            "$foo + 61\n",
            "\n",
            "$foo + 62\n",
            "\n",
            "$foo + 63\n",
            "\n",
            "$foo + 64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python '/content/drive/MyDrive/Topics in Computing Notebooks/run_generation.py' \\\n",
        "  --model_type gpt2 \\\n",
        "  --model_name_or_path gpt2 \\\n",
        "  --prompt \"hip hop\" \\\n",
        "  --stop_token \"<EOS>\" \\\n",
        "  --k 50 \\\n",
        "  --length=500 \\\n",
        "  --num_return_sequences 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aW57rHEBGQ1N",
        "outputId": "8c1e32e8-2c54-428c-dd1d-af8a640d75c0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/08/2021 03:27:56 - WARNING - __main__ - device: cpu, n_gpu: 0, 16-bits training: False\n",
            "12/08/2021 03:28:02 - INFO - __main__ - Namespace(device=device(type='cpu'), fp16=False, k=50, length=500, model_name_or_path='gpt2', model_type='gpt2', n_gpu=0, no_cuda=False, num_return_sequences=5, p=0.9, padding_text='', prefix='', prompt='hip hop', repetition_penalty=1.0, seed=42, stop_token='<EOS>', temperature=1.0, xlm_language='')\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "=== GENERATED SEQUENCE 1 ===\n",
            "hip hop to improve your brewing quality.\n",
            "\n",
            "\n",
            "This one will be a little longer, but if you'd like to help with the rest of this project (or even take part in a donation), you can get in contact with me for the following things:\n",
            "\n",
            "A small print of this poster can be found at http://sales.gizmodo.com/shop/RazerXon-4-Brewery.html<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|\n",
            "=== GENERATED SEQUENCE 2 ===\n",
            "hip hop production for the new, improved KW5, while the other two are still using the same basic design and performance concepts. While they're still very much the same, the KW5's performance was a little different. In fact, while the newer KW5 is essentially unchanged, the KW5-V2 is slightly upgraded.\n",
            "\n",
            "A key feature of the KW5-V2 is its new, improved, and smaller motor, which has two 6-volt outputs (one for each of the four main motor parts), a new high-output 1-meter-diameter aluminum crank block (which has a single 1/8-inch diameter diameter) and a new-style six-speed manual gearbox with the new manual shift ring. These motor features are still on the KW5-V2's motor specs sheet, but they're now the main thing that made the KW5-V2 unique.\n",
            "\n",
            "The larger and lighter motor also has a shorter stroke and is slightly longer. This means that this larger and lighter motor can run at more power than most other KW motors, including the KW5's other KW5s that run at more power. This has made KW5's larger motor feel more powerful and also more comfortable to use. The motor's smaller stroke means the KW5's shorter stroke makes it easier to carry your other bikes, which is what makes KW5 the most comfortable to use. KW5 also has a smaller and thinner head tube.\n",
            "\n",
            "On top of all of that, the KW5's lower-output, dual-position shifter (also called the KW5-V2), is now a two-position shifter with an extra pair of two-piston calipers, but this is only possible on the KW5. The KW5-V2 has an extra pair of rear brake calipers. KW5 has a more solid-state transmission (which has a 6-degree gearshift) and a faster rear brake than the KW5's V-6, which can handle the KW5's larger motor, but this is a more basic design that is not well suited for a touring car. The KW5 has a bigger head tube and narrower head tube.\n",
            "\n",
            "The KW5's motor output has also drastically increased. In the past, when you could get a larger motor (like the K\n",
            "=== GENERATED SEQUENCE 3 ===\n",
            "hip hop and fruit flavors that appeal to all tastes. And that sounds good! There are tons of other flavor combos and styles you can add to your own mix to give your guests some flavor that's not at home in your typical fruit and spice combo.\n",
            "\n",
            "Here's a list of the flavor combos that will make up your mix. You can find a lot more great flavors from around the Internet that will suit your tastes.\n",
            "\n",
            "3-Pin Fruit Chilled Vegetable\n",
            "\n",
            "The best part about fruit that you can add to your mix is the ability to add flavorful flavors to the mix without the added calories or carbs. The flavor combos here should be your mix staple if you're doing all the fruit flavoring, like this:\n",
            "\n",
            "2-Pin Fruit Pita Mix\n",
            "\n",
            "The flavors here are the ones that don't require a lot of fruit to be added or added to the mix. The flavors here should be something you add in between each of the two main flavors, like this:\n",
            "\n",
            "1-Pin Banana Mix\n",
            "\n",
            "This is another one that has an interesting flavor profile and doesn't require much fruit for the mix to be consistent. It's actually great for those of you who want some fruit that tastes like a banana. You can add in a little more sugar and salt in the mix.\n",
            "\n",
            "Also, if you want to add in a little bit of fiber or calcium, or a little more vitamin C and/or protein in the mix, you can add in the pineapple juice, too.\n",
            "\n",
            "If you're looking to spice up your mix, try these delicious fruit flavor combos.\n",
            "\n",
            "4-Pin Fruit Pasta Mix\n",
            "\n",
            "If you want to add flavor to your mix that isn't too overwhelming, try this one, which is a fruit flavor that has a great balance of flavor and texture. It's definitely worth the $.95 for three of these!\n",
            "\n",
            "This will add a nice sweetness to the mix while also giving it some fruit, or more, in it.\n",
            "\n",
            "Also, if you want to spice up your mix with a lot of protein, like this:\n",
            "\n",
            "If you want to spice up your mix with a little of protein and calcium, like this:\n",
            "\n",
            "This will add a nice sweetness to the mix while also giving it some fruit, or more, in it.\n",
            "\n",
            "4-Pin Fruit Cream Mix\n",
            "\n",
            "These are the ones that are really good for the mix. You may add i\n",
            "=== GENERATED SEQUENCE 4 ===\n",
            "hip hop and fruit. You don't know what you're getting until you're trying to taste a little of all of these things.\n",
            "\n",
            "For me, what I like most is when I'm cooking or serving a meal with food and ingredients. I love making new things. If that sounds too familiar to you, it is because we are in our 20s. We are very different people and we are the same food. Our families, our families live in different places. Our kids go to different places, our kids go to different places, and we can only make those food items that are unique to one particular place.\n",
            "\n",
            "I think there is a great potential to improve this. I know we are already starting to build out the kitchen and the kitchen is now going to be able to do things that are really different from what we used to do. We can't just put all the recipes together and say, \"I need to make all these recipes, and this is what I want to make.\" So when we get into the kitchen and make food we get to make something different than before, but still we need to really think about who it is we are talking about and what we are putting into our food. We are still really doing a lot of things. We are not all creating the same food.\n",
            "\n",
            "I love to tell people that we are going to do some things different in terms of how we make food. I mean I don't know that that's the right way to describe it. I just like it because I think we need to give food a little bit more attention. I think that's what's great about our food, that we're not looking to be in a certain space that we're not doing a good job of communicating the things we're doing. So it just sounds like a little bit of a contradiction because it's like saying, \"I am not that different from you, my sister, or my mom, but I am, I am.\" I'm not trying to say we are all the same. I don't know if that's true. What I like is that what we're doing is we are all trying to make a living. So that's what I think we can do really well.<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|\n",
            "=== GENERATED SEQUENCE 5 ===\n",
            "hip hop-ups (e.g., high temps, long hops, etc.), are not the most efficient method. The key for brewing is to brew in high temperature to produce a high-quality result that satisfies the taste buds (the palate). Thus, if the taste buds are already a bit sour (not a bad thing for an IPA), then using an IPA brew is not recommended.\n",
            "\n",
            "\n",
            "If the nose of your IPA is too sour, then it is good that you use your beer as a substitute. There is no need to mix up the hops to make the brew.\n",
            "\n",
            "Salty and High\n",
            "\n",
            "One problem is that some of the hops in your beer are more potent than others (e.g., Cascade hops), making it difficult for your beer to be truly high-fibre. To fix this, you'll need to work with the beer brewer to create a strong malt backbone. This should be done in two ways:\n",
            "\n",
            "Use low-carb techniques or use high-fibre techniques (e.g., hops with a low-carb content such as Amarillo or Chinook).\n",
            "\n",
            "\n",
            "Use a mix of high and low. You could also use a mix of hops that have a high hop character such as Citra or Amarillo.\n",
            "\n",
            "\n",
            "This mixture is made up of Cascade hops, IPAs and Chinooks. When using a high-fermentation beer, use the high-fermentation beer as a high-grade adjunct to ensure that the hops don't overpower the hop character. You may also use some low-fibre techniques or high-fermentation techniques to ensure that the hops don't overpower the hop character.\n",
            "\n",
            "Pricing: Some breweries will charge $9.99 (non-alcoholic and non-alcoholic beer, non-wholesale beer, craft beer, mixed-strength and limited-bodied beer) for your choice of hops and a high-fermentation beer.\n",
            "\n",
            "For brewing (non-alcoholic and non-alcoholic), please consult the Brewer's Notes.\n",
            "\n",
            "\n",
            "How much will I need?\n",
            "\n",
            "If you can afford it, the higher the price, the more expensive you will need to purchase your hops. For most non-pilgrimage IPA breweries, the actual cost is in the same range as if they were brewing from a barrel. For instance, a $20 low-pilgrimage beer is $19.95. In tha\n"
          ]
        }
      ]
    }
  ]
}